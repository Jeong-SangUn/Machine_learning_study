{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가와 성능 향상\n",
    "\n",
    "데이터를 훈련 세트와 테스트 세트로 나누는 이유는 새로운 데이터에 모델이 얼마나 잘 일반화되는지 측정하기 위함이다. 모델이 훈련 세트에 잘 맞는 것보다, 학습 과정에 없던 데이터에 대해 얼마나 잘 예측하는가가 중요하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cross-validation(교차 검증)\n",
    "\n",
    "- 일반화 성능을 평가하는 데에 트레인/테스트 데이터로 한 번 나누는 것보다 더 안정적이고 뛰어난 통계적 평가 방법\n",
    "- 교차 검증에서는 데이터를 여러번 반복해서 나누고 여러 모델을 학습함\n",
    "- 대표적으로 k-fold cross-calidation (k-겹 교차 검증)\n",
    "- 예를 들어 k=5를 선택한다면,\n",
    "\n",
    "    1) 데이터를 비슷한 크기의 부분집합 5개로 나눔\n",
    "\n",
    "    2) 첫번째 모델은 1번 폴드를 테스트 데이터로 사용, 2~5 폴드를 트레인 데이터로 사용 두번째 모델은 2번 폴드를 테스트 데이터로 사용, 1,3,4,5 폴드를 트레인 데이터로 사용\n",
    "\n",
    "    3) 이와 같이 5개의 정확도 값을 얻게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver = 'lbfgs',multi_class='auto',random_state=0, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores : [0.98039216 0.94117647 1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(logreg, iris.data, iris.target)\n",
    "\n",
    "print(\"cross validation scores : {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores : [0.96666667 1.         0.93333333 0.96666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "scores_k5 = cross_val_score(logreg, iris.data, iris.target, cv=5)\n",
    "\n",
    "print(\"cross validation scores : {}\".format(scores_k5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차 검증시 주의 사항\n",
    "- 단순한 k겹 교차 검증은 데이터가 랜덤하지 않은 경우, 특히 분류 문제에서 클래스 별로 구성된 데이터 일 때, 적용에 주의해야 한다.\n",
    "- 위와 같은 데이터 형태일 때는 model_selection 모듈 내의 KFold()를 사용하여 기본형 k겹 교차검증을 보완할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kfold = KFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores : [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"cross validation scores : {}\".format(cross_val_score(logreg, iris.data, iris.target, cv=Kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kfold1 = KFold(n_splits=3, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores : [0.98 0.96 0.96]\n"
     ]
    }
   ],
   "source": [
    "print(\"cross validation scores : {}\".format(cross_val_score(logreg, iris.data, iris.target, cv=Kfold1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임의분할 계층별 교차검증\n",
    "- 매우 유연한 교차 검증 전략\n",
    "- train_size/ test_size로 데이터 임의 분할(중복 없음)\n",
    "- 이 분할은 n_splits 횟수만큼 반복됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_shuffle_split = StratifiedShuffleSplit(train_size=0.7,\n",
    "                                                 test_size=0.3, n_splits = 10,\n",
    "                                                  random_state= 0)\n",
    "\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv = stratified_shuffle_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores : [1.         0.97777778 0.97777778 0.97777778 0.95555556 0.95555556\n",
      " 0.97777778 0.97777778 0.97777778 0.95555556]\n"
     ]
    }
   ],
   "source": [
    "print(\"scores : {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [144 117 115  22  28  38  57 111  91 112  45  56  98  58   1   7 135  69\n",
      "  80 119 131  96   4  31  93  82   5  63 137 143 140  83 126 132   8  10\n",
      "  13  73  33  15 130  62 138  16  27  32  52  75  26  95  79  60 108  41\n",
      "  76  77  87  71 148  11  74 146  84  66 128  94 118  48  59 125 106 124\n",
      " 145  17 107  40  49 104  97  20  30  25  42  14  92 105 122 116  35 101\n",
      "   2  18  70  64  72  53  43 114 133  29 127  78  34 120 141] \n",
      " Test: [136 142  39  44  50  23  90 149  46  55  21 147  47 123  67 134  68  65\n",
      "  51   0  54 103  24  81 129 102 113 100  89 110  99  19   6  88  86 121\n",
      "  85  37   9  61  36 109   3  12 139]\n",
      "Train: [102  11 121 119 108 131  52 101  93  91 149  70 126  34 113  66  20  92\n",
      "  90 141  75  31  81  57  62  99 100 107  74   7 118  67  63  18 146 138\n",
      "   6  56 148  10  40   5  96   4  14  49  37  83  86  95 115 140 103  59\n",
      "  41 128  45   8  44  24  71   2  39  55 144 114  64 139  47  13 111  43\n",
      "  38 134 135 112  51 106 132  33 110 142  69 105  98  23  73  35   3  53\n",
      "  82 122  15  87  79 109  19  94  42  26  88 117  12   1  72] \n",
      " Test: [ 89  85  32  61 129  68  48 124  76  58  60  46   0  28 120 104   9  78\n",
      " 116  22  80 145  17  30  36 123  54  97 133  25 147  77  27  16  84 143\n",
      "  21 137 136  50 127 125  65 130  29]\n",
      "Train: [115  30  11 130 123 122  98 103 116  58 129  91   0 139 105   4  61  63\n",
      "  28  44  89 142  29 111  48   6  43   9  68  71 131 128 100 113  94  45\n",
      "  69 102  80 114  14  87  52  65  72 148  18  46  74  54  81  32 106 108\n",
      " 107  90  24 101  26  10  88  76  86  56  55 120 109  27   7  85  51 127\n",
      "  49  41   3  77 119  70  97  66  99 124 117  33  39 147  34  60  95 121\n",
      " 145 134 143   2  19  23  78  40 118  15  12  20  38 138  53] \n",
      " Test: [144 112  42  59 141 126 136  75 104  35  82  62  21  84  16  64 110  17\n",
      "  67  57  47  92  83   1 132 146 140   5   8 125  73  37  13  22  25 133\n",
      "  50 137  96 135 149  36  79  31  93]\n",
      "Train: [ 95  87 117  71 108  75  62   2  93 125  31 113 118  19  53  84  56   4\n",
      " 121  66  45  96  12  67  72   9  13  89 106  20  92  57 145  42 101 137\n",
      " 120 110  79  73  27  58  41  76   7  69  64  43   5  18 122  77  80 131\n",
      " 128  28  78 112  91 140   3 100 104  44  14  36  81  32 124 132 149  61\n",
      "  11   6  52  47  48 136  68  50 127  25 109 138  22  21  26 134  17 146\n",
      " 130  63 143 119  83  15 148 142  34  40  60 133  82 139  10] \n",
      " Test: [141  70  30  39  85  51  49 147 144  55  33  29  97 135 102   0 116  98\n",
      "  90 126  16 123  54  38 115  24  74  65  35  99 114   8  46 107  88  94\n",
      " 111 105  23  59   1  37  86 129 103]\n",
      "Train: [ 33  49   3  38  91 124  61 129 144 137   9 139  43  71  15  84  40  58\n",
      "  96  66  26  73  41  76 125 138  59 109  57 140  70 122  99  19 121  60\n",
      "  77  11 126  46   6  21 131  35 108  68 146  90  18  39 123  54  24   1\n",
      "  72  78 141 103  55 114  12 115  81 145 116  52  13 135  10 111  53 104\n",
      "  32 149  92  51  36  30  63 118 127  65   0  89 134  75 106   5 120  87\n",
      " 105 112  50  23  97  20  25  74 133  47  82 130   4   2  48] \n",
      " Test: [143  27  56  62 117  14 142  85 128 102 148  42  16 147   7 110   8  67\n",
      " 119  28  29  44 101  93 132  22 113  80  95 107  94  88  69  34  31  98\n",
      "  45  83 100  37  86  17  64  79 136]\n",
      "Train: [ 70  11  39 105  93  64  78  22 104  56  86  79  52   7 136  27 130  50\n",
      "  61  75  20  72 119 127  53  46 103 126 149  67 143 112  33  99  45  63\n",
      "  59 113  69  54  21  48  24  43  13  65 111  60  81  85 115 106  73  18\n",
      " 108  37  29  15  58   5  16 135  25  76  55  12   3 146   6   2 118  34\n",
      " 116 125 124 145 148 131  87  71 123  19  26 129  92  40 147 132  82  90\n",
      " 107  88 109  28   0 133 144  98 137  94  10   1  42 114  41] \n",
      " Test: [ 51 120  44  80  91 142  62  74  23  57 100  35  30   4  38  66  84  47\n",
      "   9  17 117  97 102  68  95  31 122 110 141  14  83 138 128   8 121  96\n",
      "  32 101 139  49  77 140  36 134  89]\n",
      "Train: [ 76  58 139  65   6  66   0  26  91  53 129 130  73 101 116  57 146  64\n",
      "  19 145 123  20  36  82 126  50 140 104 124  96  79   1  47 149  13 134\n",
      "  61 107  99 105  14  78  98   5 117 142  75 112  49 103  16 128  41  34\n",
      "  80  85 106  51 102  32 115 118 113 100  71  17  70  18  68  44 148 141\n",
      "  55  15 137  89  60 114  46  27  30  74  10 125   3  28  88  45 120  43\n",
      "  90  95  63  83  42  12  52  23   9  35  39 136 108  29  62] \n",
      " Test: [ 21  94 143 121  40  97  37 122 109  84  87 119  81   2 144  31  86  77\n",
      "  72  93  48   4 138  38  11 110  69 131  24  67  33  25   7   8 132 147\n",
      "  92 127  22  59 135  56 111 133  54]\n",
      "Train: [131 149 138  89  73  14 109  18  66 101  34  43  77   0  61  60 130  44\n",
      "  69 108  71  82 104  45 100  50  37  94   6  67  31  72   7  16  54  68\n",
      " 125 129  27  70 115 144 137  64  17 135  32  63 106  76 124  86  10  88\n",
      " 145  56   9 116   2  20  38  79  81  22  74  12   8  47  13  28 123 112\n",
      "  93   1 136  19  46  35  90   4  97 134 102  75  65 128  25  80  24 119\n",
      " 111  98  62 110  91  84 132 141 107 122  23 118 139 133  40] \n",
      " Test: [113  29 142  59 147  53 148  48 121  78 127  57 143  55  58   3  92  11\n",
      "  42  83  36  99   5  87 146 105  85  96 117  49  33  52  95 114  21 126\n",
      "  51  26  39 120  30  41 103  15 140]\n",
      "Train: [ 74  35   8  78 144  10  11  80  39  98 122   3 146  44 135 127  81  57\n",
      "  86  29  60  52  22  36 111  47  17  41 145  31  69  15  65 137  30  94\n",
      "  62  14 101  45  64 119  67  34 120  54 141 112 121  82  38  68  23  73\n",
      " 106   1 102 116  70 132  20  50  19 142   9  96  40 129 125  89  24  66\n",
      " 131 105 117  63 107 100  51  55   4   0 138  42 139 147  83 140  85 103\n",
      "  90  49  28  88   7  72 124  58  99  32  75  16 134 126 148] \n",
      " Test: [113 123  92  43  76 109 143  27  56  59  97  84 104  33  12 136  25  91\n",
      "  18  95  26 114  48 118  46  53 108  21  13  71  37 149  61   6  87  93\n",
      " 133 110  79  77   5 128   2 130 115]\n",
      "Train: [ 40 125  65   3 126  74  55  64 140 144 145  85  36 138  97  76 136 148\n",
      "  88 118  53  54  32  60  80  58 115 106  66  31 111   8  29  75  52  96\n",
      "  82  39  25  68  16  57  93  56  18  92  13 104  11 110  34 101  91  15\n",
      "  69  21  59  42 117 105  86  48  78 142 146  23 147   7 131 127  70  38\n",
      "  83  24  30  27  17 137  47   2 130 139  99  90 109   6  26  35 143 112\n",
      "  19   9  72  95 133 149  20  84 113 121 129  37 116 100  28] \n",
      " Test: [103 120  50   5  14  12  46  22 107  94  43 108 141  62  33  87 114  63\n",
      "  81 122  44  45   4  41  73  67 134 128 135 119  51  98   0  79 124 102\n",
      "  49  61   1 132  89  71 123  10  77]\n"
     ]
    }
   ],
   "source": [
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "for train_index, test_index in stratified_shuffle_split.split(X,y):\n",
    "    print('Train:',train_index,'\\n','Test:',test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores : [1.         0.97777778 0.97777778 0.97777778 0.95555556 0.95555556\n",
      " 0.97777778 0.97777778 0.97777778 0.95555556]\n"
     ]
    }
   ],
   "source": [
    "print(\"cross validation scores : {}\".format(cross_val_score(logreg, iris.data, iris.target, cv=stratified_shuffle_split)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = cross_val_score(logreg, iris.data, iris.target, cv=stratified_shuffle_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 35, 35], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "- 매개변수를 튜닝하여 일반화 성능을 개선하고자 함\n",
    "- 관심 있는 매개변수들을 대상으로 가능한 조합을 시도하여 최적의 값을 찾음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size:112\n",
      " Test set size:38\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "\n",
    "print(\"Train set size:{}\\n Test set size:{}\".format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.974\n",
      "Train Score: 0.9732142857142857\n",
      "parameters: {'gamma': 0.001, 'C': 100}\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        svm = SVC(gamma= gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        \n",
    "        test_score = svm.score(X_test, y_test)\n",
    "        \n",
    "        if test_score > best_score:\n",
    "            best_score = test_score\n",
    "            best_parameters = {'gamma': gamma, 'C':C}\n",
    "            train_score = svm.score(X_train, y_train)\n",
    "            \n",
    "print('Best Score: {}'.format(np.round(best_score,3)))\n",
    "print('Train Score: {}'.format(train_score))\n",
    "print('parameters: {}'.format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\<Note\\>\n",
    "\n",
    "- 위의 결과에 따라 모델의 정확도가 97%라고 결론 짓는 것은 위험한 것일수 있음\n",
    "- 여러가지 매개변수를 조합하여 테스트 세트의 정확도가 가장 높은 조합을 선택했으나,\n",
    "- 이 정확도는 새로운 데이터에 이어지지 않을 수 있다\n",
    "- 매개변수를 조정하기 위해 테스트 세트를 이미 사용했기 때문에 최종 모델의 정확성은 새로운 데이터가 생성될 때까지 알 수 없다.\n",
    "- 즉, 최종 평가를 위해서는 모델을 만들고 튜닝할 때 사용하지 않은 독립된 데이터 셋이 필요하다.\n",
    "- 애당초 데이터셋을 3개로 나누어 이 문제를 해결 할 수 있다.\n",
    "    | 훈련세트(train data) | 검증세트(validation data) | 테스트 세트(test data)\n",
    "- 그러나 이 역시 데이터의 수가 적을때는 부정확 할수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size:84\n",
      "Validaion set size:28\n",
      "Test set size:38\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X,y,test_size=0.25, random_state=0)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval,y_trainval,test_size=0.25, random_state=1)\n",
    "\n",
    "print(\"Train set size:{}\\nValidaion set size:{}\\nTest set size:{}\".format(X_train.shape[0],X_valid.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score in validation: 0.964\n",
      "parameters1: {'gamma': 0.001, 'C': 10}\n",
      "Test Score with best parameters: 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        svm = SVC(gamma= gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        \n",
    "        score = svm.score(X_valid, y_valid)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters1 = {'gamma': gamma, 'C':C}\n",
    "            \n",
    "svm = SVC(**best_parameters1)\n",
    "svm.fit(X_trainval, y_trainval)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "\n",
    "print('Best Score in validation: {}'.format(np.round(best_score,3)))\n",
    "print('parameters1: {}'.format(best_parameters1))\n",
    "print('Test Score with best parameters: {}'.format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
