{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "max_features = 10000\n",
    "\n",
    "maxlen = 500\n",
    "\n",
    "# 정수 리스트로 데이터를 로드합니다.\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "#리스트를 2D로 만듬\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen = maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layer 및 모델 프레임워크\n",
    "\n",
    "- Embedding 층은 크기가 (samples, sequence_length)인 2D 정수 텐서를 입력으로 받음\n",
    "- output은 (samples, sequence_length, embedding_dimensionality)인 3D 실수형 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4001      \n",
      "=================================================================\n",
      "Total params: 84,001\n",
      "Trainable params: 84,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "# Embedding 층의 출력 크기는 (samples, maxlen*8)\n",
    "model.add(Embedding(input_dim = max_features, output_dim=8, input_length=maxlen))\n",
    "# 3D 임베딩 텐서를 (samples, maxlen*8)크기의 2D 텐서로 펼칩니다.\n",
    "model.add(Flatten())\n",
    "# 분류기 추가\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                128032    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 208,065\n",
      "Trainable params: 208,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Embedding(input_dim = max_features, output_dim=8, input_length=maxlen))\n",
    "model1.add(Flatten())\n",
    "\n",
    "# 학습층 추가\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 3s 152us/step - loss: 0.4743 - acc: 0.7530 - val_loss: 0.2956 - val_acc: 0.8762\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 2s 125us/step - loss: 0.2227 - acc: 0.9125 - val_loss: 0.2850 - val_acc: 0.8840\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 2s 125us/step - loss: 0.1409 - acc: 0.9478 - val_loss: 0.3194 - val_acc: 0.8788\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 0.0842 - acc: 0.9709 - val_loss: 0.3907 - val_acc: 0.8708\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 3s 137us/step - loss: 0.0459 - acc: 0.9855 - val_loss: 0.5138 - val_acc: 0.8622\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.0236 - acc: 0.9933 - val_loss: 0.6407 - val_acc: 0.8542\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 0.0111 - acc: 0.9968 - val_loss: 0.8253 - val_acc: 0.8442\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 0.0049 - acc: 0.9987 - val_loss: 1.0217 - val_acc: 0.8382\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 0.0021 - acc: 0.9993 - val_loss: 1.2153 - val_acc: 0.8274\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 3s 125us/step - loss: 9.4855e-04 - acc: 0.9997 - val_loss: 1.3623 - val_acc: 0.8284\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(x_train, y_train,\n",
    "                     epochs=10,\n",
    "                     batch_size=32,\n",
    "                     validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 3s 136us/step - loss: 0.4626 - acc: 0.7634 - val_loss: 0.3071 - val_acc: 0.8720\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 3s 131us/step - loss: 0.2183 - acc: 0.9122 - val_loss: 0.2906 - val_acc: 0.8792\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 0.1367 - acc: 0.9506 - val_loss: 0.3377 - val_acc: 0.8764\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 3s 125us/step - loss: 0.0821 - acc: 0.9714 - val_loss: 0.4102 - val_acc: 0.8694\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 0.0451 - acc: 0.9858 - val_loss: 0.5255 - val_acc: 0.8624\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.0214 - acc: 0.9931 - val_loss: 0.6907 - val_acc: 0.8544\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.0102 - acc: 0.9971 - val_loss: 0.8487 - val_acc: 0.8466\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 3s 143us/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.9732 - val_acc: 0.8454\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 0.0015 - acc: 0.9998 - val_loss: 1.2430 - val_acc: 0.8352\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 8.6635e-04 - acc: 0.9998 - val_loss: 1.5391 - val_acc: 0.8216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x205d46ef0f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Embedding, Input\n",
    "\n",
    "inputs = Input(shape=(None,))\n",
    "embedding = Embedding(input_dim = max_features, output_dim=8, input_length=maxlen)(inputs)\n",
    "output1 = Flatten()(embedding)\n",
    "output2 = Dense(32, activation='relu')(output1)\n",
    "predictions = Dense(1, activation='sigmoid')(output2)\n",
    "api_model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "api_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "api_model.fit(x_train, y_train,\n",
    "             epochs=10,\n",
    "             batch_size=32,\n",
    "             validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                128032    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 208,065\n",
      "Trainable params: 208,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "api_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 규제 방식\n",
    "\n",
    "1. hidden node, layer의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                128032    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 208,065\n",
      "Trainable params: 208,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 3s 151us/step - loss: 0.5176 - acc: 0.7440 - val_loss: 0.3566 - val_acc: 0.8736\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 0.2968 - acc: 0.8990 - val_loss: 0.3178 - val_acc: 0.8878\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 0.2327 - acc: 0.9264 - val_loss: 0.3231 - val_acc: 0.8790\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 3s 134us/step - loss: 0.1921 - acc: 0.9448 - val_loss: 0.3387 - val_acc: 0.8752\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 0.1551 - acc: 0.9615 - val_loss: 0.3522 - val_acc: 0.8792\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.1237 - acc: 0.9734 - val_loss: 0.3999 - val_acc: 0.8688\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.0977 - acc: 0.9831 - val_loss: 0.4190 - val_acc: 0.8660\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 3s 134us/step - loss: 0.0766 - acc: 0.9882 - val_loss: 0.4337 - val_acc: 0.8654\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.0622 - acc: 0.9912 - val_loss: 0.4668 - val_acc: 0.8640\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.0506 - acc: 0.9942 - val_loss: 0.5389 - val_acc: 0.8562\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras import regularizers\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Embedding(input_dim = max_features, output_dim=8, input_length=maxlen))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model2.summary()\n",
    "\n",
    "history2 = model2.fit(x_train, y_train,\n",
    "                     epochs=10,\n",
    "                     batch_size=32,\n",
    "                     validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dropout 추가 ,l2 규제 강화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 8)            0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                128032    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 208,065\n",
      "Trainable params: 208,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 4s 225us/step - loss: 0.7683 - acc: 0.5856 - val_loss: 0.6802 - val_acc: 0.6948\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 4s 199us/step - loss: 0.6082 - acc: 0.7975 - val_loss: 0.5416 - val_acc: 0.8390\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 4s 209us/step - loss: 0.4974 - acc: 0.8521 - val_loss: 0.4777 - val_acc: 0.8590\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 4s 213us/step - loss: 0.4598 - acc: 0.8647 - val_loss: 0.4647 - val_acc: 0.8612\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 4s 210us/step - loss: 0.4391 - acc: 0.8741 - val_loss: 0.4549 - val_acc: 0.8702\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 4s 209us/step - loss: 0.4281 - acc: 0.8793 - val_loss: 0.4442 - val_acc: 0.8714\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 4s 213us/step - loss: 0.4155 - acc: 0.8867 - val_loss: 0.4388 - val_acc: 0.8746\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 4s 188us/step - loss: 0.4131 - acc: 0.8862 - val_loss: 0.4423 - val_acc: 0.8782\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 4s 187us/step - loss: 0.4063 - acc: 0.8893 - val_loss: 0.4435 - val_acc: 0.8814\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 4s 185us/step - loss: 0.4021 - acc: 0.8935 - val_loss: 0.4421 - val_acc: 0.8780\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Embedding(input_dim = max_features, output_dim=8, input_length=maxlen))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model3.summary()\n",
    "\n",
    "history3 = model3.fit(x_train, y_train,\n",
    "                     epochs=10,\n",
    "                     batch_size=32,\n",
    "                     validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 40us/step\n",
      "test_acc:  0.8744400143623352\n"
     ]
    }
   ],
   "source": [
    "test_loss3, test_acc3 = model3.evaluate(x_test, y_test)\n",
    "\n",
    "print('test_acc: ',test_acc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN(Recurrent Neural Network)\n",
    "- DNN,CNN은 메모리가 없음\n",
    "- 따라서, 시퀀스가 있는 데이터를 시퀀스를 고려하여 처리하지는 못한다.\n",
    "- 순환신경망(Recurrent Neural Network)은 처리한 정보를 상태(state)에 저장함\n",
    "- RNN은 내부에 루프를 가진 신경망의 한 종류\n",
    "- RNN의 상태(state)는 2개의 다른 시퀀스를 처리하는 사이에 재설정됨.\n",
    "\n",
    "```python\n",
    "state_t = 0 # state가 내부적으로 만들어짐\n",
    "for input in input_sequence:\n",
    "    ouput_t = activation(dot(W, input_t) + dot(U,state_t) +b)\n",
    "    state_t = output_t\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 322,113\n",
      "Trainable params: 322,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.6134 - acc: 0.6606 - val_loss: 0.4559 - val_acc: 0.8076\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.3888 - acc: 0.8335 - val_loss: 0.3539 - val_acc: 0.8546\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.3073 - acc: 0.8776 - val_loss: 0.4726 - val_acc: 0.7948\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.2448 - acc: 0.9075 - val_loss: 0.4295 - val_acc: 0.8402\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.1968 - acc: 0.9267 - val_loss: 0.4752 - val_acc: 0.8472\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.1587 - acc: 0.9411 - val_loss: 0.4138 - val_acc: 0.8538\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 30s 1ms/step - loss: 0.1179 - acc: 0.9591 - val_loss: 0.4418 - val_acc: 0.8390\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.0833 - acc: 0.9725 - val_loss: 0.5334 - val_acc: 0.8148\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0584 - acc: 0.9815 - val_loss: 0.5080 - val_acc: 0.8486\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0486 - acc: 0.9841 - val_loss: 0.5657 - val_acc: 0.8290\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Embedding\n",
    "\n",
    "rnn_model = Sequential()\n",
    "\n",
    "rnn_model.add(Embedding(input_dim = max_features, output_dim=32))\n",
    "rnn_model.add(SimpleRNN(32))\n",
    "rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "rnn_model.summary()\n",
    "\n",
    "rnn_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "rnn_history = rnn_model.fit(x_train, y_train,\n",
    "                     epochs=10,\n",
    "                     batch_size=128,\n",
    "                     validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 2.1465 - acc: 0.5556 - val_loss: 1.0148 - val_acc: 0.7376\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.6813 - acc: 0.7580 - val_loss: 0.4514 - val_acc: 0.8288\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 30s 1ms/step - loss: 0.4634 - acc: 0.8285 - val_loss: 0.4981 - val_acc: 0.7976\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.4011 - acc: 0.8597 - val_loss: 0.4380 - val_acc: 0.8272\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.3493 - acc: 0.8788 - val_loss: 0.5101 - val_acc: 0.7648\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.3239 - acc: 0.8887 - val_loss: 0.4422 - val_acc: 0.8146\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.2997 - acc: 0.9012 - val_loss: 0.6550 - val_acc: 0.7906\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 30s 1ms/step - loss: 0.2940 - acc: 0.9053 - val_loss: 0.3492 - val_acc: 0.8714\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 30s 1ms/step - loss: 0.2575 - acc: 0.9168 - val_loss: 0.3548 - val_acc: 0.8718\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 30s 1ms/step - loss: 0.2653 - acc: 0.9115 - val_loss: 0.4831 - val_acc: 0.7844\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Embedding\n",
    "import tensorflow as tf\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    rnn_model = Sequential()\n",
    "    rnn_model.add(Embedding(input_dim = max_features, output_dim=32))\n",
    "    rnn_model.add(SimpleRNN(32, kernel_regularizer=regularizers.l2(0.1)))\n",
    "    rnn_model.add(Dropout(0.5))\n",
    "    rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    rnn_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    rnn_history = rnn_model.fit(x_train, y_train,\n",
    "                         epochs=10,\n",
    "                         batch_size=128,\n",
    "                         validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM(Long Short Term Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 79s 4ms/step - loss: 0.5219 - acc: 0.7297 - val_loss: 0.3516 - val_acc: 0.8512\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 77s 4ms/step - loss: 0.2771 - acc: 0.8928 - val_loss: 0.3097 - val_acc: 0.8690\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 76s 4ms/step - loss: 0.1957 - acc: 0.9293 - val_loss: 0.3281 - val_acc: 0.8790\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 76s 4ms/step - loss: 0.1509 - acc: 0.9496 - val_loss: 0.3248 - val_acc: 0.8804\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 76s 4ms/step - loss: 0.1153 - acc: 0.9639 - val_loss: 0.3530 - val_acc: 0.8776\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 76s 4ms/step - loss: 0.1025 - acc: 0.9682 - val_loss: 0.3830 - val_acc: 0.8794\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 77s 4ms/step - loss: 0.0801 - acc: 0.9759 - val_loss: 0.4135 - val_acc: 0.8766\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 77s 4ms/step - loss: 0.0778 - acc: 0.9761 - val_loss: 0.4686 - val_acc: 0.8702\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 77s 4ms/step - loss: 0.0624 - acc: 0.9815 - val_loss: 0.4506 - val_acc: 0.8712\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 78s 4ms/step - loss: 0.0796 - acc: 0.9748 - val_loss: 0.4669 - val_acc: 0.8716\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=10,\n",
    "                   batch_size=128,\n",
    "                   validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import CuDNNLSTM #GPU를 위한 LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(CuDNNLSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=10,\n",
    "                   batch_size=128,\n",
    "                   validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## callback : EarlyStopping & ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [\n",
    "    \n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_acc',\n",
    "        patience = 3),\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = 'imdb_lstm.h5',\n",
    "        monitor = 'val_loss',\n",
    "        save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 46s 2ms/step - loss: 0.5271 - acc: 0.7533 - val_loss: 0.3881 - val_acc: 0.8488\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 47s 2ms/step - loss: 0.3016 - acc: 0.8872 - val_loss: 0.2967 - val_acc: 0.8828\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 46s 2ms/step - loss: 0.2309 - acc: 0.9159 - val_loss: 0.4183 - val_acc: 0.8184\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 46s 2ms/step - loss: 0.1937 - acc: 0.9319 - val_loss: 0.3026 - val_acc: 0.8678\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 46s 2ms/step - loss: 0.1637 - acc: 0.9428 - val_loss: 0.2904 - val_acc: 0.8866\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 47s 2ms/step - loss: 0.1452 - acc: 0.9513 - val_loss: 0.3922 - val_acc: 0.8726\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 46s 2ms/step - loss: 0.1304 - acc: 0.9552 - val_loss: 0.3150 - val_acc: 0.8774\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 48s 2ms/step - loss: 0.1186 - acc: 0.9604 - val_loss: 0.5840 - val_acc: 0.8354\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=10,\n",
    "                   batch_size=128,\n",
    "                   validation_split=0.2,\n",
    "                   callbacks = callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
